<style>
/* Generic table styling */
table { border-collapse: collapse; width: 100%; }
th, td { padding: .55rem .7rem; border: 1px solid #e5e7eb; }

/* Header color */
thead th { background: #6ec56eff; color: #fff; }

/* Justify normal body text (not headings) */
p { text-align: justify; }

/* Optional: better spacing & hyphenation */
p {
  hyphens: auto;          /* enable smart hyphenation */
  overflow-wrap: anywhere;/* avoid overflow on long words/URLs */
  line-height: 1.6;
}

/* Don’t justify code blocks/lists by mistake */
pre, code, kbd, samp, li { text-align: left; }

/* Zebra striping (even rows) 
tbody tr:nth-child(even) { background: #f3f3f3ff; }
*/
</style>


**Programme**
: BSc (Hons) in Computing in Games Development
: BSc (Hons) in Computing in Software Development

**Stage**
: 2

**Module**
: [Object-Oriented Programming](https://courses.dkit.ie/index.cfm/page/module/moduleId/55573/deliveryperiodid/1066)

**Title**
: GCA1 — Index & Insight — Hash, compare, and report

**Weight**
: 20% of final module grade

**Late Submission**
:  Institute policy on late submission will apply (see [here](https://www.dkit.ie/about/policies/continuous-assessment-procedures))

**Academic Integrity**
: Institute policy on academic integrity will apply (see [here](https://www.dkit.ie/about/policies/academic-integrity-policy-and-procedures))

**Generative AI Tools**
: Institute policy on the use of Generative AI tools will apply (see [here](https://www.dkit.ie/about/policies/generative-artificial-intelligence-ai-and-your-assessments-a-guide-for-students))

**CA Cover Sheet**
: A signed CA cover sheet must be included and may be found (see [here](https://www.dkit.ie/about/policies/continuous-assessment-procedures))

## 1. Learning Outcomes

| Code | Learning Outcome |
|:--:|:--|
| **MLO1** | Solve intermediate-to-advanced programming problems using object-oriented design and GUI/console-based input–process–output models. |
| **MLO2** | Employ object-oriented design concepts, models, patterns, tools, and techniques to develop modularised software solutions. |
| **MLO3** | Evaluate and select appropriate data structures (Collections) and algorithms to solve problems and implement solutions. |
| **MLO5** | Use code-management, testing, and debugging techniques in software development. |

## 2. Overview

This two-stage assessment asks you and a partner to design and build a **small, real-world-inspired Java data system**. You will model a realistic dataset, store it in memory, and perform operations such as loading, sorting, searching, and reporting.

Typical use cases include: maintaining a **player leaderboard**, tracking **products or orders**, managing **customers or bookings**, or cataloguing **events, items, or films**.

Your project grows from a basic prototype into a robust mini-application that demonstrates **encapsulation**, **validation**, **ordering**, and **testing** — a **data‑management engine** that could sit inside a larger game, business, or analytics app.

Across the two stages you will:
- Design an entity class with a **diverse set of validated fields**.  
- Load and query records using Java Collections (`ArrayList`, `LinkedList`, `HashSet`, `HashMap`).  
- Apply software craftsmanship principles: [DRY](../../../shared/general/dry-notes.md), [defensive coding](../../../shared/general/defensive-coding-notes.md), and strong [commit messages](../../../shared/general/commit-message-guidelines.md).  
- Demonstrate validation by **detecting, logging, and skipping** invalid data rather than throwing exceptions.  
- Present findings through short written justifications, defensive-coding examples, and an interview.

Groups may **propose their own domain and dataset** (e.g., esports, retail, music, fitness). Discuss with your lecturer your team proposal by **Week 6** for approval.

### Stage Structure

| Stage | Week | Weight | Focus |
|:--|:--:|:--:|:--|
| **Stage 1 – Design & Prototype** | Week 9 | 40% | Define your entity, build a prototype using Lists, and justify your design in a README report. |
| **Stage 2 – Implementation & Verification** | Week 12 | 60% | Extend your code with equality, hashing, and testing. Verify correctness through JUnit; optional visualisation. |

### Repository Branches and Tagging
Pairs must be confirmed by **Monday of Week 6**. Maintain a **public GitHub repo** with branches:
- `stage1` (Stage 1 development)  
- `stage2` (branched from `stage1` after feedback)

### Reference Notes
Short notes on **commit messages**, **defensive coding**, and **DRY** live in:
```
notes/shared/general/
```

## 3. Functional Requirements (60% of total)

### Stage 1 – Design & Prototype  *(Functional = 24 marks)*

| # | Component | Description | Weight |
|:--:|:--|:--|:--:|
| 1 | **Entity Definition** | Java class (one CSV row) with **≥ 7 distinct fields**: 2 Strings, 1 int, 1 double, 1 boolean, 1 `LocalDate`, 1 `LocalDateTime`; encapsulated; setter validation (trim/blank/range checks). | 6% |
| 2 | **CSV Loading (10 records)** | Load `sample_10.csv` (10 exact records). Display count of valid rows and sample output. | 5% |
| 3 | **Data Structure Selection** | Store entities in `ArrayList` or `LinkedList` with justification; demonstrate iteration and safe removal. | 3% |
| 4 | **Ordering & Searching** | One natural order (`Comparable`) and one `Comparator`. Demonstrate both. | 4% |
| 5 | **DRY & Defensive Coding** | Apply DRY and early‑exit checks for null/empty/invalid input; helper methods for repeated logic. | 3% |
| 6 | **Reporting & Output** | Brief printed summary/table of loaded data and sorted results. | 3% |

### Stage 2 – Implementation & Verification  *(Functional = 36 marks)*

| # | Component | Description | Weight |
|:--:|:--|:--|:--:|
| 1 | **Extended Dataset (1000)** | Load `dataset_1000.csv` (exactly 1000). May be generated with [Mockaroo](https://www.mockaroo.com/). | 5% |
| 2 | **Entity Enhancements** | Add validated fields or helpers (derived values, formatted output); preserve encapsulation. | 6% |
| 3 | **Collections & Lookup** | Add `HashSet` or `HashMap` for duplicate control or fast lookup. | 5% |
| 4 | **Equality & Hashing** | Consistent `equals`/`hashCode` based on stable identifiers; demonstrate effects. | 6% |
| 5 | **Advanced Queries, Reports & CSV Export** | ≥2 queries (date range, top‑N, frequencies). Summaries + CSV export using same schema. | 6% |
| 6 | **Testing Demonstration** | Driver methods or JUnit tests for sorting, search, duplicates. | 5% |
| 7 | **Defensive & Reusable Code** | Maintain DRY and early‑exit principles across new code. | 3% |

### CSV Dataset Summary
| File | Purpose | Count | Notes |
|:--|:--|:--:|:--|
| `sample_10.csv` | Small, easy to review | 10 | Include diverse edge values. |
| `dataset_1000.csv` | Large dataset | 1000 | UTF‑8 CSV (comma). Can use Mockaroo. |


### Minimum Entity Fields
Entity **must** include **≥ 7 fields** across diverse types; derived/computed fields **don’t count**. Use ISO‑8601 in CSV (`YYYY‑MM‑DD`, `YYYY‑MM‑DDThh:mm:ss`). Validation should **detect, log, and skip** invalid values.

## 4. Design Requirements
- Clear class decomposition, encapsulation, cohesion.  
- Justified collection choices.  
- Consistent ordering and equality semantics.  
- JavaDoc for classes and public methods.  
- Record design decisions in the report.

## 5. Testing Requirements
- Use **JUnit 5**.  
- Stage 1 indicative coverage ≥ **35%** (core classes).  
- Stage 2 target coverage ≥ **75%** ([Jacoco](https://youtu.be/AS7Akff7mzo)).  
- Positive, negative, edge-case tests.  
- Coverage screenshot in `/docs/coverage/`.

## 6. Reporting Requirements (with word limits)

**Word-count applies to prose only** (exclude code, tables, diagrams, headings, references).

### Stage 1 – Reporting Sections
| Section | Content | Word limit |
|---|---|---|
| Solution Domain (both)| Dataset purpose, users, constraints, key fields. | 120–250 |
| Design Justification (both)| Entity, collection choice, ordering strategy. | 200–350 |
| Defensive Coding 1 (4–6) (both)| Where/why early‑exit/validation used. | 220–400 total |
| Reflection (per student) | Lessons; next steps. | 100–150 each |
| Commit Contributions (both) | Comment on balance with evidence/graphs. | 50–120 |

### Stage 2 – Reporting Sections
| Section | Content | Word limit |
|---|---|---|
| Equality & Hashing Rationale (both)| Identity fields; immutability notes. | 180–300 |
| Testing Summary (both)| JUnit approach; coverage result and interpretation. | 180–300 |
| Defensive Coding 2 (4–6) (both)| Where/why checks used; consequences if omitted. | 240–420 total |
| Reflections (both) | How Stage 1 feedback improved Stage 2. | 150–250 |
| Commit Contributions (both)| Analysis of Stage 2 balance. | 60–120 |
| Final References (both)| Harvard style. | — |
| Implementation Matrix (final) | Updated ✓/✗ table. | — |

## 7. Process & Quality Weightings

### Repository Quality & Workflow [10 marks]
Evidence of a healthy process in GitHub: regular, incremental commits; clear imperative messages; balanced contributions; correct branches/tags; concise README updates. 

**Marking (1–10):** 
- 1–3 weak
- 4–6 acceptable
- 7–8 good
- 9–10 excellent.

### Unit Testing & Coverage [10 marks]
Automated tests and measured coverage: Stage 1 baseline ≥35%; Stage 2 target ≥75%; meaningful assertions and edge cases; include coverage evidence.

**Marking (1–10):** 
- 1–3 weak
- 4–6 acceptable
- 7–8 good
- 9–10 excellent.

### Reporting & Documentation Quality [20 marks]
The README/report provides **evidence of reasoning and professionalism**. See Reporting sections for structure.  

**Key components:** design rationale; defensive‑coding evidence (4–6); testing discussion; contribution matrix; reflections; clear formatting. 

**Marking (1–10):** 
- 1–3 weak
- 4–6 acceptable
- 7–8 proficient
- 9–10 excellent.

## 8. Submission Notes
| Item | Detail |
|:--|:--|
| **Submission** | GitHub URL via Moodle (one per pair). |
| **Branching** | `stage1` and `stage2` branches required and used. |
| **Presentation / Interview** | 5–6 min demo + Q&A; both students present. |
| **References** | Harvard style. |
| **Plagiarism Policy** | DkIT Academic Integrity policy applies; reused code must be cited. |
| **Use of AI** | Allowed for research/boilerplate only; declare in README. Undeclared use = plagiarism. |
| **Late Policy** | See DkIT Continuous Assessment Procedures (link [here](https://www.dkit.ie/about/policies/continuous-assessment-procedures)). |

## 9. Assignment Cover Sheet
- One signed DkIT CA Cover Sheet **per group** covering Stage 1 and Stage 2.  
- Submit via Moodle in **Week 12** with Stage 2 repo link.
- Download from <https://www.dkit.ie/about/policies/continuous-assessment-procedures>

## 10. Assessment Compliance 
- **GitHub is mandatory.** Public repo with required branches/tags.  
- **Report with Effort/Implementation Matrix is mandatory.**  
- **Non‑compliance = Not graded.** Missing repo or required report/matrix counts as **non‑submission**.

## Appendix A — Assessment Rubrics

### Stage 1 — Design & Prototype (Week 9, 40%)

**Functional Subtotal (24%)**

| Component | Weight | Mark Range (1–10) | Criteria |
|:--|:--:|:--:|:--|
| Entity Definition | 6% | 1–10 | 1–3: trivial/incomplete fields; 4–6: basic with partial validation; 7–8: solid, encapsulated, validated; 9–10: exemplary. |
| CSV Loading (10) | 5% | 1–10 | 1–3: fragile parsing; 4–6: loads file; 7–8: robust checks; 9–10: reusable loader + summary. |
| Data Structure Selection | 3% | 1–10 | 1–3: weak choice/justification; 4–6: adequate; 7–8: reasoned; 9–10: well‑argued with usage evidence. |
| Ordering & Searching | 4% | 1–10 | 1–3: incorrect/missing; 4–6: partly working; 7–8: correct Comparable + Comparator; 9–10: polished/consistent. |
| DRY & Defensive Coding | 3% | 1–10 | 1–3: repetition; 4–6: some guards; 7–8: helpers + early‑exit; 9–10: highly modular/clear. |
| Reporting & Output | 3% | 1–10 | 1–3 unclear; 4–6 basic; 7–8 neat; 9–10 professional. |

**Process & Quality (16%)**

| Component | Weight | Mark Range (1–10) | Criteria |
|:--|:--:|:--:|:--|
| Repository Quality & Workflow | 4% | 1–10 | Frequency, clarity, balance; branches/tags; meaningful messages. |
| Unit Testing & Coverage (baseline) | 4% | 1–10 | Driver/JUnit for ordering/search; ≥35% coverage; evidence included. |
| Reporting & Documentation Quality | 8% | 1–10 | Concise, well‑structured write‑up with diagrams/screens; reflects Stage 1 scope. |

**Total Stage 1 = 40%**

### Stage 2 — Implementation & Verification (Week 12, 60%)

**Functional Subtotal (36%)**

| Component | Weight | Mark Range (1–10) | Criteria |
|:--|:--:|:--:|:--|
| Extended Dataset (1000) | 5% | 1–10 | 1–3 unreliable; 4–6 loads with minor issues; 7–8 efficient/robust; 9–10 excellent clarity/performance. |
| Entity Enhancements | 6% | 1–10 | 1–3 minimal; 4–6 useful additions; 7–8 well‑chosen + validated; 9–10 thoughtful + documented. |
| Collections & Lookup | 5% | 1–10 | 1–3 weak use; 4–6 correct; 7–8 effective duplicate control/lookup; 9–10 clear efficiency rationale. |
| Equality & Hashing | 6% | 1–10 | 1–3 inconsistent/missing; 4–6 basic; 7–8 correct & verified; 9–10 exemplary. |
| Advanced Queries & CSV Export | 6% | 1–10 | 1–3 minimal; 4–6 functional; 7–8 meaningful analyses; 9–10 insightful + exportable. |
| Testing Demonstration | 5% | 1–10 | 1–3 few tests; 4–6 basic; 7–8 solid suite; 9–10 thorough evidence. |
| Defensive & Reusable Code | 3% | 1–10 | 1–3 fragile; 4–6 some reuse/checks; 7–8 consistent; 9–10 very clean. |

**Process & Quality (24%)**

| Component | Weight | Mark Range (1–10) | Criteria |
|:--|:--:|:--:|:--|
| Repository Quality & Workflow | 6% | 1–10 | Balanced activity; clear messages; branches/tags; PRs/reviews where used. |
| Unit Testing & Coverage | 6% | 1–10 | JUnit 5 suite; ≥75% coverage; clear assertions; coverage evidence. |
| Reporting & Documentation (incl. Presentation/Interview) | 12% | 1–10 | Professional report + live demo/interview; clear results, rationale, and reflection. |
**Total Stage 2 = 60%**

## Appendix B — Glossary of Key Terms

| Term | Meaning |
|:--|:--|
| **Encapsulation** | Bundling of data and methods; private fields + public API. |
| **Validation** | Check inputs; detect, log, and skip invalid values. |
| **DRY** | Don’t Repeat Yourself; centralise shared logic. |
| **Defensive Coding** | Anticipate invalid states; use early‑exit guards. |
| **Comparable / Comparator** | Interfaces to define object ordering. |
| **Equality & Hashing** | `equals` and `hashCode` semantics for collections. |
| **Commit Message** | Short, clear description of a change. |
| **JUnit** | Java unit testing framework. |
