| **Item**                | **Details**                                                                                                                                                                                     |
| :---------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Programme**           | BSc (Hons) in Computing in Games Development; BSc (Hons) in Computing in Software Development                                                                                                   |
| **Stage**               | 2                                                                                                                                                                                               |
| **Module**              | COMP C8Z03 (Object-Oriented Programming)                                                                                                                                                        |
| **Weight**              | 20% of module grade                                                                                                                                                                             |
| **Submission**          | GitHub URL via Moodle (one per pair). Private repo required.                                                                                                                                     |
| **Oral Defense**        | Students will normally demonstrate their project and defend it in a brief interview. Your demonstrated understanding of the work presented is a major factor in grading.                        |
| **Late Submission**     | Institute policy on late submission will apply (see [here](https://www.dkit.ie/about/policies/continuous-assessment-procedures)).                                                               |
| **Academic Integrity**  | Institute policy on academic integrity will apply (see [here](https://www.dkit.ie/about/policies/academic-integrity-policy-and-procedures)).                                                    |
| **Generative AI Tools** | Institute policy on the use of Generative AI tools will apply (see [here](https://www.dkit.ie/about/policies/generative-artificial-intelligence-ai-and-your-assessments-a-guide-for-students)). |
| **CA Cover Sheet**      | A signed CA cover sheet must be included and may be found (see [here](https://www.dkit.ie/about/policies/continuous-assessment-procedures)).                                                    |
## 1) Overview
Build a small **Java data system** (e.g., leaderboard, products, customers, bookings, events) in **pairs** across **two stages**:
- Model a realistic entity with validated fields.
- Load and query records using Java Collections.
- Implement ordering (Comparable/Comparator) and, later, equality & hashing.
- Practise defensive coding and DRY.
- Write a concise report and defend your work in interview.

> Each student group **must** email your lecturer a 150–200 word domain description by **1:00 PM Wednesday of Week 6 for approval** (one email per pair; include both names and student IDs). Begin significant code or data work only after written approval. Any later domain change requires re-approval by email.

## 2) Learning outcomes assessed
- **MLO1:** Solve intermediate-to-advanced problems using OOP and console/GUI I‑P‑O.  
- **MLO2:** Use OOP concepts, models, patterns, tools, and techniques to build modular solutions.  
- **MLO3:** Choose appropriate Collections and algorithms and implement them.  
- **MLO5:** Use code-management, testing, and debugging techniques.

## 3) Timeline and weighting
- **Stage 1 — Design & Prototype (Week 9, 40%)**
  - Define your entity and build a working prototype using Lists.
  - Justify key design choices in a short README.

- **Stage 2 — Implementation & Verification (Week 12, 60%)**
  - Extend code with equality, hashing, testing, and larger data.
  - Verify with JUnit test and coverage and present findings. Includes **demo + interview**.

**Repo structure**
- Confirm pairs by **Monday of Week 6**.  
- Branches: `stage1` and `stage2` (create `stage2` after Stage 1 feedback).

## 4) Data & validation (requirements for both stages)

| Requirement | Details |
|:--|:--|
| CSV files | `sample_10.csv` (10 rows with edge cases) and `dataset_1000.csv` (1000 rows, UTF‑8, comma). |
| Entity (fields) | **≥7 distinct fields:** 2 × `String`, 1 × `int`, 1 × `double`, 1 × `boolean`, 1 × `LocalDate`, 1 × `LocalDateTime`. |
| Date formats | Use ISO‑8601 in CSV (e.g., `2025-10-17`, `2025-10-17T14:05:00`). |
| Encapsulation | Private fields; validate in setters/constructors (trim, blank/range checks). |
| Invalid data | Detect, **log**, and **skip** bad rows (do not crash on expected errors). |
| Output | Provide a concise printed summary and/or CSV export as required per stage. |

## 5) Stage 1 — What to deliver (40%)

### Marking: Functional (24%)

| Criterion | Description | Weight |
|:--|:--|:--:|
| Entity Definition | ≥7 typed fields; encapsulated; validation with clear messages. | 6% |
| CSV Loading | Load exactly 10 rows; print valid-count and a sample listing. | 5% |
| Data Structure Choice | Use `ArrayList` or `LinkedList` with justification; show iteration and safe removal. | 3% |
| Ordering & Searching | Implement `Comparable` (natural order) and one `Comparator`; show search/sort. | 4% |
| DRY & Defensive Coding | Early exits, helper methods for repeated logic; no duplication hotspots. | 3% |
| Reporting & Output | Brief, readable console output or formatted listing. | 3% |

### Marking: Process & Quality (16%)

| Criterion | Description | Weight |
|:--|:--|:--:|
| Repository Quality | Regular, meaningful commits; branches/tags; balanced contributions. | 4% |
| Unit Testing & Coverage (baseline) | Driver/JUnit test and coverage for ordering/search; **≥35%** coverage; include evidence. | 4% |
| Reporting & Documentation | Concise README/report: design rationale, defensive examples, contribution matrix, reflection. | 8% |

**Reporting guidance (prose, not including code/figures)**

| Section | Who writes it | Word count |
|:--|:--:|:--:|
| Solution Domain | both | 120–250 |
| Design Justification | both | 200–350 |
| Defensive Coding 1 (4–6 examples) | both | 220–400 total |
| Reflection | each | 100–150 |
| Commit Contributions | both | 50–120 |

## 6) Stage 2 — What to deliver (60%)

### Marking: Functional (36%)

| Criterion | Description | Weight |
|:--|:--|:--:|
| Extended Dataset | Load exactly 1000 rows; efficient, robust loader with error handling. | 5% |
| Entity Enhancements | Validated additions/helpers; preserve encapsulation. | 6% |
| Collections & Lookup | Introduce `HashSet`/`HashMap` for duplicates or fast lookup; show usage. | 5% |
| Equality & Hashing | Consistent `equals`/`hashCode` on stable identifiers; demonstrate effects. | 6% |
| Advanced Queries & CSV Export | 2+ queries (date range, top‑N, frequencies); summaries + CSV export (same schema). | 6% |
| Testing Demonstration | JUnit tests for sorting/search/duplicates; clear assertions and naming. | 5% |
| Defensive & Reusable Code | Consistent checks and reuse; avoid repetition. | 3% |

### Marking: Process & Quality (24%)

| Criterion | Description | Weight |
|:--|:--|:--:|
| Repository Quality | Balanced activity; clear messages; branches/tags; PRs/reviews if used. | 6% |
| Unit Testing & Coverage | **≥75%** coverage target (JUnit test and coverage evidence); include positive, negative, edge cases. | 6% |
| Report + Presentation/Interview | Professional report; **live demo + interview**; clear results, rationale, and reflection. | 12% |

**Reporting guidance (prose, not including code/figures)**

| Section | Who writes it | Word count |
|:--|:--:|:--:|
| Equality & Hashing Rationale | both | 180–300 |
| Testing Summary | both | 180–300 |
| Defensive Coding 2 (4–6 examples) | both | 240–420 total |
| Reflections | both | 150–250 |
| Commit Contributions | both | 60–120 |
| Final References | both | Harvard style |

**Interview mapping**  
- Your **interview performance** may influence multiple criteria where understanding must be evidenced.  
- If the oral defense reveals a lack of understanding of submitted code, this will be reflected in the **Stage 1 (retrospectively) and Stage 2** grades in line with academic integrity and module policy.

## 7) Practicalities & policies

| Item | Rule |
|:--|:--|
| GitHub | **Mandatory** private repo with lecturer as collaborator; submit URL on Moodle. Missing repo ⇒ **not graded**. |
| JUnit Tests | **Mandatory** inclusion of JUnit tests for each stage. Missing unit tests ⇒ **not graded**. |
| Effort/Implementation Matrix | **Mandatory** in report/README. Missing ⇒ **non‑submission**. |
| Generative AI | Permitted for research/boilerplate; **declare usage** in README. Undeclared use ⇒ plagiarism. |
| References | Harvard style. |
| Late submissions | Institute procedures apply. |
| Cover Sheet | One signed CA cover sheet per group; upload with Stage 2 link in Week 12. |

## 8) Quick glossary

| Term | Plain meaning |
|:--|:--|
| Encapsulation | Private fields, controlled access via methods. |
| Validation | Check inputs; log and skip invalid values. |
| DRY | “Do not repeat yourself” — centralise shared logic. |
| Defensive coding | Anticipate invalid states; use early‑exit guards. |
| Comparable/Comparator | Define object ordering (natural vs custom). |
| Equality & hashing | `equals`/`hashCode` for correct behaviour in sets/maps. |
| JUnit | Java unit testing framework. |

## 9. Submission Checklist

| **Item**                                     | **Stage 1 (Week 9)**                                                                                                                                                                                  | **Stage 2 (Week 12)**                                                                                                                                                                                                  |
| :------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **GitHub repository & Moodle link** | Repo is private with lecturer as collaborator. <br>Submit **repo URL** on Moodle                                                                                                                                               | Repo remains private. <br>Submit **same repo URL** on Moodle                                                                                                                                                      |
| **Branch / Tag**                             | Work on branch **`stage1`**<br>Optional tag: `stage1-submitted`                                                                                                                               | Create branch **`stage2`** from Stage 1 feedback<br>Optional tag: `stage2-submitted`                                                                                                                           |
| **Java source code**                         | Compiles and runs<br>Entity with **≥7 fields** (2×String, int, double, boolean, LocalDate, LocalDateTime)<br>Encapsulation + validation                                                   | Enhancements complete (helpers, invariants)<br>Equality & hashing implemented (`equals`/`hashCode`)                                                                                                            |
| **CSV datasets**                             | Include **`sample_10.csv`** (10 rows with edge cases)                                                                                                                                             | Include **`dataset_1000.csv`** (1000 rows, UTF-8, comma)                                                                                                                                                           |
| **Unit tests & coverage (evidence in repo)** | JUnit tests for ordering/search<br>**≥35%** coverage (e.g., JUnit report in repo)                                                                                                            | JUnit 5 tests incl. equals/hash, duplicates, edge cases<br>**≥75%** coverage (JUnit report in repo)                                                                                                           |
| **Ordering / Collections**                   | `Comparable` (natural order)<br>One `Comparator` + sort/search demo                                                                                                                           | Add `HashSet`/`HashMap` for lookup/duplicate handling                                                                                                                                                              |
| **Output evidence**                          | Console summary showing load counts + sorted sample                                                                                                                                               | **2+ queries** (e.g., range/top-N/frequency)<br>CSV **export** (schema-compatible)                                                                                                                             |
| **README / Report**                          | Domain overview (120–250 words)<br>Design justification (200–350)<br>**4–6 defensive coding** examples (220–400 total)<br>Contribution matrix<br>Reflection (100–150 per student) | Equality & hashing rationale (180–300)<br>Testing summary (180–300)<br>**4–6 defensive coding** examples (240–420 total)<br>Reflections (150–250)<br>Contribution matrix<br>Harvard references |
| **Presentation / Demo**                      | —                                                                                                                                                                                                     | Live demo of features & results                                                                                                                                                                                    |
| **Interview (Oral Defense)**                 | —                                                                                                                                                                                                     | Brief interview defending design, code, and tests (**major factor in grading**)                                                                                                                                    |
| **CA Cover Sheet**                           | —                                                                                                                                                                                                     | Signed **CA cover sheet** uploaded with Stage 2                                                                                                                                                                    |
| **Policy compliance**                        | Academic Integrity; Generative-AI usage declared in README                                                                                                                                        | Academic Integrity; Generative-AI usage declared in README; Institute late policy applies                                                                                                                          |

> Tip: put evidence where we can find it fast—e.g., `/reports/`, `/tests/`, `/data/`, and note paths in the README.


## Appendix A — Complete Assessment Rubric

> **How to read this rubric:** Each criterion shows a weight (% of overall CA1 mark). Performance bands describe expected evidence. Mark within a band should reflect consistency, completeness, and polish. Evidence can appear in code, commits, README/report, demo, tests, and the interview.

### A.1 Stage 1 — Design & Prototype (40%)

| Criterion (Weight) | Excellent (A) | Good (B) | Satisfactory (C) | Limited (D/E) | Unacceptable (F/NS) |
|:--|:--|:--|:--|:--|:--|
| **Entity Definition (6%)** | 7+ well‑typed fields; names and ranges justified; validation clear and consistent; no duplicated logic. | 7+ fields; mostly appropriate; minor naming/range/validation issues. | Minimum met; validation exists but patchy; some unclear names. | Fields/validation inconsistent; weak justification; signs of copy‑paste. | Missing or trivial model; no validation; cannot proceed. |
| **CSV Loading (5%)** | Robust loader; trims/keeps empties; clear logging; prints valid count + sample; handles malformed lines gracefully. | Mostly robust; handles common errors; minor logging/printing weaknesses. | Loads 10 rows; basic error handling; prints output. | Fragile; skips logic unclear; misleading output. | Fails to load or crashes; no usable output. |
| **Data Structure Choice (3%)** | Justifies `ArrayList` vs `LinkedList` with access/mutation pattern evidence; safe iterator removal demonstrated. | Choice reasoned; minor misuse. | Choice present; limited justification; removal safe or partially correct. | Weak/incorrect justification; unsafe removal. | No rationale; incorrect usage; runtime errors. |
| **Ordering & Searching (4%)** | Correct `Comparable`; one clear `Comparator`; consistent with equals where relevant; search/sort demoed and explained. | Correct implementations; small edge cases missed. | Works for common cases; edge cases not discussed. | Partially working; misunderstandings visible. | Not implemented or incorrect (e.g., violates comparator contract). |
| **DRY & Defensive Coding (3%)** | Clear helpers, guard clauses, centralised parsing; repetition minimal. | Some helpers; a little repetition remains. | DRY attempts visible; repetition in places. | Repetition common; guards inconsistent. | No DRY; no guards; frequent ad‑hoc code. |
| **Reporting & Output (3%)** | Concise, readable output; aligns with README; shows sorted/filtered examples. | Mostly clear; occasional verbosity. | Adequate; minimal formatting. | Hard to follow; lacks structure. | Missing or unreadable. |
| **Repository Quality (4%)** | Regular, meaningful commits; tags/branches; clear pair balance. | Good cadence; mostly clear messages. | Adequate commits; uneven contributions. | Sparse or bursty commits; unclear authorship. | Single dump; no evidence of process. |
| **Unit Testing & Coverage ≥35% (4%)** | Clear AAA tests; boundary/negative cases; coverage evidence linked. | Good variety; coverage adequate. | Basic happy‑path tests; minimal evidence. | Few tests; flaky or poorly named. | No tests or non‑running tests. |
| **Reporting & Documentation (8%)** | Focused README/report: domain, design rationale, 4–6 defensive examples, contribution matrix, reflections; within word ranges. | Complete but slightly verbose/short; minor gaps. | Meets minimum content; uneven depth. | Incomplete or off‑topic; misses key items. | Missing or plagiarised. |

**Stage 1 subtotal: 40%**

---

### A.2 Stage 2 — Implementation & Verification (60%)

| Criterion (Weight) | Excellent (A) | Good (B) | Satisfactory (C) | Limited (D/E) | Unacceptable (F/NS) |
|:--|:--|:--|:--|:--|:--|
| **Extended Dataset (5%)** | Efficient 1000‑row load; robust parsing; clear error logs; timings/notes on performance. | Robust with minor inefficiencies. | Loads correctly; basic logging. | Fragile or slow; unclear logging. | Fails to load reliably. |
| **Entity Enhancements (6%)** | Helpful helpers/utilities; invariants maintained; no leaks; defensive copies where needed. | Enhancements mostly solid; small leaks/edge issues. | Adequate additions; some ad‑hoc code. | Weak or inconsistent; side‑effects/leaks present. | No meaningful enhancement or broken invariants. |
| **Collections & Lookup (5%)** | Appropriate use of `HashSet`/`HashMap`; duplicate detection/lookup explained with examples. | Correct choice; minor gaps in examples. | Works for common cases; sparse rationale. | Misused or inefficient structures. | Not implemented or incorrect behaviour. |
| **Equality & Hashing (6%)** | Correct `equals`/`hashCode` over stable identity; demos show effects in sets/maps; contract documented. | Correct for most cases; minor contract omissions. | Works in typical cases; limited demos. | Partially correct; risks violations. | Incorrect or missing; breaks collections. |
| **Advanced Queries & CSV Export (6%)** | 2+ meaningful queries (range/top‑N/frequency) with clear output; CSV export schema‑compatible. | Queries correct; small formatting/export issues. | Queries present; basic export. | Queries simplistic; export inconsistent. | Missing queries/export. |
| **Testing Demonstration (5%)** | JUnit 5 battery for sorting/search/duplicates/equals‑hash; good naming and assertions. | Good coverage of key paths. | Basic positives and some negatives. | Minimal or shallow tests. | None or non‑running. |
| **Defensive & Reusable Code (3%)** | Consistent guard/validation; utilities reused across stages; minimal duplication. | Mostly consistent; a few repetitions. | Acceptable; repetition persists. | Inconsistent; brittle. | Absent. |
| **Repository Quality (6%)** | Balanced contributions; PRs/reviews (if used); clear commit history. | Good overall; minor balance issues. | Adequate; some uneven work. | Poor hygiene or unclear history. | Dumped or opaque history. |
| **Unit Testing & Coverage ≥75% (6%)** | Clear evidence (JUnit); mix of boundary/negative/edge; mutation or property‑based tests considered. | Strong coverage; mostly meaningful. | Meets target; some trivial tests. | Below target or weak tests. | No evidence or far below target. |
| **Report + Presentation/Interview (12%)** | Professional report; strong demo; **interview** shows deep understanding of design, code, and tests; justifies trade‑offs. | Clear report/demo; good interview answers. | Adequate report; basic demo; interview acceptable. | Weak report/demo; interview uncertain. | Missing report or demo; interview fails to evidence understanding. |

**Stage 2 subtotal: 60%**

> **Oral Defense policy:** Interview evidence may adjust Stage 2 marks for criteria where understanding must be demonstrated. Where the defense reveals a lack of understanding of submitted code, this will be reflected in the **Stage 1 and Stage 2** grade in line with academic integrity and module policy.

**Total for CA1:** 100%

